<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>ConvertCSVLoop06-1_Extract</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/</directory>
    <parameters>
      <parameter>
        <name>DB_DRIVER</name>
        <default_value>org.apache.derby.jdbc.ClientDriver</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_PASSWORDS</name>
        <default_value>admin,admin</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_TABLES</name>
        <default_value>TB1,TB2</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_URL</name>
        <default_value>jdbc:derby://localhost/testDB;create=true</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_USERS</name>
        <default_value>admin,admin</default_value>
        <description />
      </parameter>
      <parameter>
        <name>IN_FILE</name>
        <default_value>C:/data/home/eiichi/Workspaces/space2/TrialPentahoDI/src/test/ktr/data_text.csv</default_value>
        <description />
      </parameter>
      <parameter>
        <name>START_ROWS</name>
        <default_value>9,9</default_value>
        <description />
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection />
        <schema />
        <table />
        <size_limit_lines />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection />
        <schema />
        <table />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user />
    <created_date>2018/06/23 01:17:31.064</created_date>
    <modified_user>-</modified_user>
    <modified_date>2010/09/30 20:22:22.679</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>【Extract】
・テーブル名をdb_tableフィールドに入れる。
・Extractでdb_user変数を設定しているため、Dummyを挟まないとtable_ouputで利用できない

【Table output】
・db_tableフィールドにあるテーブル名に対してinsertを行う。</note>
      <xloc>320</xloc>
      <yloc>48</yloc>
      <width>459</width>
      <heigth>105</heigth>
      <fontname>Yu Gothic UI</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>Derby_local_testDB</name>
    <server>localhost</server>
    <type>GENERIC</type>
    <access>Native</access>
    <database>testDB</database>
    <port>1527</port>
    <username>${db_user}</username>
    <password>Encrypted 2be98afc86aa7f2e4cb79ce71da9fa6d4</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>CUSTOM_DRIVER_CLASS</code>
        <attribute>${DB_DRIVER}</attribute>
      </attribute>
      <attribute>
        <code>CUSTOM_URL</code>
        <attribute>${DB_URL}</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>1527</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Table loop</from>
      <to>Extract</to>
      <enabled>Y</enabled>
    </hop>
    <hop>
      <from>Dummy for setVariable</from>
      <to>Table output</to>
      <enabled>N</enabled>
    </hop>
    <hop>
      <from>Extract</from>
      <to>TableOut</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Dummy for setVariable</name>
    <type>Dummy</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>624</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Extract</name>
    <type>UserDefinedJavaClass</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <definitions>
      <definition>
        <class_type>TRANSFORM_CLASS</class_type>
        <class_name>Processor</class_name>
        <class_source>import java.io.*;
import java.nio.file.*;
import java.util.*;
import org.pentaho.di.core.row.value.*;

	/* ktr側で設定されているパラメータ */
	static private String PARAM_IN_FILE = "IN_FILE";


	/* 前のステップから渡されたフィールド */
	static private String FIELD_DB_TABLE = "db_table";
	static private String FIELD_DB_USER = "db_user";
	static private String FIELD_DB_PASS = "db_pass";
	static private String FIELD_START_ROW = "start_row";

	static private String[] FIELDS = {
			FIELD_DB_TABLE,
			FIELD_DB_USER,
			FIELD_DB_PASS,
			FIELD_START_ROW
	};

	/**
	 * 変換を実行する内部クラス
	 */
	private class Extractor {

		private BufferedReader _reader = null;

		/**
		 * ファイルを読み込み初期化
		 * @throws KettleException
		 */
		public void init(int startRow) throws KettleException {
			try {
				/* パラメータで指定されたファイルを読み込む */
				String filePathStr = getVariable(PARAM_IN_FILE);
				logBasic("In FilePath=" + filePathStr);
				Path filePath = Paths.get(filePathStr, new String[0]);
				_reader = Files.newBufferedReader(filePath);

				/* 最初の行まで読み込む */
				for (int i = 0; i &lt; startRow; i++) {
					_reader.readLine();
				}
			} catch (IOException e) {
				throwAsKettleException(e);
			}
		}

		/**
		 * インポート対象のカラム名情報を返却する。
		 *
		 * @return
		 */
		public ValueMetaInterface[] getRowColumns() {
			return new ValueMetaInterface[] {
					new ValueMetaString("col1"),
					new ValueMetaString("col2")
			};
		}

		/**
		 * ファイルを1行読み込んで配列を返す.
		 *
		 * @return 読み込んだデータ。終端の場合はnul値とする。
		 */
		public Object[] getRowData() throws KettleException {
			if (_reader == null) {
				return null;
			}
			String line = null;
			try {
				line = _reader.readLine();
			} catch (IOException e) {
				throwAsKettleException(e);
			}
			if (line == null) {
				return null;
			}

			String[] columnDatas = line.split(",");

			/*
			 * 必要に応じて変換処理
			 */
			// 大文字にする
			columnDatas[1] = toUpper(columnDatas[1]);

			return columnDatas;
		}

		public String toUpper(String indata) {
			return indata.toUpperCase();
		}

		public void close() throws KettleException {
			if (_reader != null) {
				try {
					_reader.close();
				} catch (IOException e) {
					throwAsKettleException(e);
				}
			}
		}

		private void throwAsKettleException(Throwable e) throws KettleException {
			logError("エラーが発生", e);
			throw new KettleException(e);
		}
	}

	Extractor extractor = new Extractor();

	String _tableName = "";
	static int PROCESS_COUNT = 2;
	private boolean _process_contiue = false;

	/**
	 * @return 次の行へ継続する場合はtrue, 終了する場合はfalse
	 */
	public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException {

		/* 最初の1回目(1行目)はfirst == trueとなる */
		if (first) {
			first = false;
			logBasic("first");
		}

		/* processの途中ではない場合(_process_contiue == false)の場合は
		 * テーブル名を前のステップから取得。
		 * null値になった場合は終了 */
		if (!_process_contiue) {

			/* 前のステップからのフィールド値を取得 */
			Object[] rowFromPrivStep = getRow();
			if (rowFromPrivStep == null) {
				logBasic("inputRow==null");
				setOutputDone();
				return false;
			}
			String[] fieldValues = getAllField(FIELDS, rowFromPrivStep);

			/* 必要なフィールド値を変数に保存 */
			_tableName = fieldValues[0];
			int startRow = Integer.parseInt(fieldValues[3]);

			/* コンバータの初期化 */
			extractor.init(startRow);

		}
		_process_contiue = false;

		/*
		 * テーブルに対する変換を実行
		 *
		 * PROCESS_COUNT毎に処理を分割する
		 */
		Object[] rowData = null;
		int count = 0;
		while ((rowData = extractor.getRowData()) != null) {
			/* データの先頭にテーブル名を入れる */
			Object[] rowDataWithTable = new Object[rowData.length + 1];
			System.arraycopy(new String[] { _tableName }, 0, rowDataWithTable, 0, 1);
			System.arraycopy(rowData, 0, rowDataWithTable, 1, rowData.length);

			/*
			 * 出力する列データを設定
			 * クリアしてから再設定することで途中でカラム構成が変わっても対応する。
			 * 1列目はテーブル名を入れる
			 * */
			RowMetaInterface newFields = new RowMeta();
			newFields.addValueMeta(new ValueMetaString(FIELD_DB_TABLE));
			ValueMetaInterface[] columns = extractor.getRowColumns();
			for (int i = 0; i &lt; columns.length; i++) {
				newFields.addValueMeta(columns[i]);
			}
			data.outputRowMeta.clear();
			data.outputRowMeta.addRowMeta(newFields);

			/*
			 * 1行のデータを出力
			 */
			putRow(data.outputRowMeta, rowDataWithTable);
			logBasic("putRow");

			count++;
			if (count >= PROCESS_COUNT) {
				_process_contiue = true;
				break;
			}
		}

		/* processが終了した時(_process_contiue==true)のみ
		 *  コンバータのクローズ */
		if (!_process_contiue) {
			extractor.close();
		}

		return true;

	}

	private String[] getAllField(String[] fieldKeys, Object[] rowData) throws KettleException {
		String[] values = new String[fieldKeys.length];

		for (int i = 0; i &lt; fieldKeys.length; i++) {
			values[i] = get(Fields.In, fieldKeys[i]).getString(rowData);
			logDebug("Get Field: " + fieldKeys[i] + "=" + values[i]);
		}

		return values;
	}</class_source>
      </definition>
    </definitions>
    <fields>
      <field>
        <field_name>db_table</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>db_user</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>db_pass</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>start_row</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
    </fields>
    <clear_result_fields>N</clear_result_fields>
    <info_steps />
    <target_steps />
    <usage_parameters />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>432</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table loop</name>
    <type>UserDefinedJavaClass</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <definitions>
      <definition>
        <class_type>TRANSFORM_CLASS</class_type>
        <class_name>Processor</class_name>
        <class_source>	/* ktrのパラメータとして受け取る */
	static private String PARAM_DB_TABLES = "DB_TABLES";
	static private String PARAM_DB_USERS = "DB_USERS";
	static private String PARAM_DB_PASSWORDS = "DB_PASSWORDS";
	static private String PARAM_START_ROWS = "START_ROWS";

	/* 次のステップへフィールドとして渡す */
	static private String FIELD_DB_TABLE = "db_table";
	static private String FIELD_DB_USER = "db_user";
	static private String FIELD_DB_PASS = "db_pass";
	static private String FIELD_START_ROW = "start_row";


	/* PARAMとFIELDをまとめたもの。個数と順序で対応していることが前提 */
	static private String[] PARAMS = {
			PARAM_DB_TABLES,
			PARAM_DB_USERS,
			PARAM_DB_PASSWORDS,
			PARAM_START_ROWS
	};
	static private String[] FIELDS = {
			FIELD_DB_TABLE,
			FIELD_DB_USER,
			FIELD_DB_PASS,
			FIELD_START_ROW
	};

	private String[][] _allParams = null;
	private int _currentIdx = 0;

	/**
	 * @return 次の行へ継続する場合はtrue, 終了する場合はfalse
	 */
	public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException {

		/* 最初の1回目(1行目)はfirst == trueとなる */
		if (first) {
			first = false;
			logDebug("first");

			/* パラメータをカンマ区切りして取得 */
			_allParams = getAllParams(PARAMS);
		}

		/* カレントのデータを取得してouputDataに設定 */
		String currentParams[] = getParams(_allParams, _currentIdx);
		Object[] outputField = RowDataUtil.allocateRowData(FIELDS.length);
		for (int i = 0; i &lt; FIELDS.length; i++) {
			logDebug("Set Field: " + FIELDS[i] + "=" + currentParams[i]);
			get(Fields.Out, FIELDS[i]).setValue(outputField, currentParams[i]);
		}

		/* 次のステップへフィールドで渡す */
		putRow(data.outputRowMeta, outputField);

		/* 全てのdb_table(_paramVariables[0])を渡したら終了する */
		_currentIdx++;
		if (_currentIdx >= _allParams[0].length) {
			logDebug("Finish");
			setOutputDone();
			return false;
		}

		return true;
	}

	private String[][] getAllParams(String[] paramKeys) {
		String[][] variables = new String[paramKeys.length][];
		for (int i = 0; i &lt; paramKeys.length; i++) {
			String[] vals = getVariable(paramKeys[i]).split(",");
			variables[i] = vals;
		}

		for (int i = 0; i &lt; variables.length; i++) {
			for (int j = 0; j &lt; variables[i].length; j++) {
				logDebug("AllVariables[" + i + "][" + j + "]: " + variables[i][j]);
			}
		}


		return variables;
	}

	private String[] getParams(String[][] allParams, int index) {
		String[] variables = new String[allParams.length];
		for (int i = 0; i &lt; variables.length; i++) {
			variables[i] = allParams[i][index];
			logDebug("CurrentVariable[" + i + "]: " + variables[i]);
		}
		return variables;
	}</class_source>
      </definition>
    </definitions>
    <fields>
      <field>
        <field_name>db_table</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>db_user</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>db_pass</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
      <field>
        <field_name>start_row</field_name>
        <field_type>String</field_type>
        <field_length>-1</field_length>
        <field_precision>-1</field_precision>
      </field>
    </fields>
    <clear_result_fields>N</clear_result_fields>
    <info_steps />
    <target_steps />
    <usage_parameters />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>256</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table output</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>Derby_local_testDB</connection>
    <schema>APP</schema>
    <table />
    <commit>1000</commit>
    <truncate>N</truncate>
    <ignore_errors>Y</ignore_errors>
    <use_batch>N</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>Y</tablename_in_field>
    <tablename_field>db_table</tablename_field>
    <tablename_in_table>N</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>784</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>TableOut</name>
    <type>TransExecutor</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <specification_method>filename</specification_method>
    <trans_object_id />
    <trans_name />
    <filename>${Internal.Entry.Current.Directory}/44_ConvertCSVLoop06-2_TableOut.ktr</filename>
    <directory_path />
    <group_size>1</group_size>
    <group_field />
    <group_time />
    <parameters>
      <variablemapping>
        <variable>${db_table}</variable>
        <field>db_table</field>
        <input />
      </variablemapping>
      <variablemapping>
        <variable>${db_user}</variable>
        <field>db_user</field>
        <input />
      </variablemapping>
      <variablemapping>
        <variable>${db_pass}</variable>
        <field>db_pass</field>
        <input />
      </variablemapping>
      <variablemapping>
        <variable>${start_row}</variable>
        <field>start_row</field>
        <input />
      </variablemapping>
      <inherit_all_vars>N</inherit_all_vars>
    </parameters>
    <execution_result_target_step />
    <execution_time_field>ExecutionTime</execution_time_field>
    <execution_result_field>ExecutionResult</execution_result_field>
    <execution_errors_field>ExecutionNrErrors</execution_errors_field>
    <execution_lines_read_field>ExecutionLinesRead</execution_lines_read_field>
    <execution_lines_written_field>ExecutionLinesWritten</execution_lines_written_field>
    <execution_lines_input_field>ExecutionLinesInput</execution_lines_input_field>
    <execution_lines_output_field>ExecutionLinesOutput</execution_lines_output_field>
    <execution_lines_rejected_field>ExecutionLinesRejected</execution_lines_rejected_field>
    <execution_lines_updated_field>ExecutionLinesUpdated</execution_lines_updated_field>
    <execution_lines_deleted_field>ExecutionLinesDeleted</execution_lines_deleted_field>
    <execution_files_retrieved_field>ExecutionFilesRetrieved</execution_files_retrieved_field>
    <execution_exit_status_field>ExecutionExitStatus</execution_exit_status_field>
    <execution_log_text_field>ExecutionLogText</execution_log_text_field>
    <execution_log_channelid_field>ExecutionLogChannelId</execution_log_channelid_field>
    <result_rows_target_step />
    <result_files_target_step />
    <result_files_file_name_field>FileName</result_files_file_name_field>
    <executors_output_step />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>704</xloc>
      <yloc>304</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
