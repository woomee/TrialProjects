<?xml version="1.0" encoding="UTF-8"?>
<transformation>
  <info>
    <name>47_ConvertCSVLoop08-2_Extract</name>
    <description />
    <extended_description />
    <trans_version />
    <trans_type>Normal</trans_type>
    <trans_status>0</trans_status>
    <directory>/</directory>
    <parameters>
      <parameter>
        <name>DB_DRIVER</name>
        <default_value>org.apache.derby.jdbc.ClientDriver</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_PASS</name>
        <default_value>admin</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_SCHEMA</name>
        <default_value>APP</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_TABLE</name>
        <default_value>TB1</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_URL</name>
        <default_value>jdbc:derby://localhost/testDB;create=true</default_value>
        <description />
      </parameter>
      <parameter>
        <name>DB_USER</name>
        <default_value>admin</default_value>
        <description />
      </parameter>
      <parameter>
        <name>IN_FILE</name>
        <default_value>C:/data/home/eiichi/Workspaces/space2/TrialPentahoDI/src/test/ktr/data_text_2.csv</default_value>
        <description />
      </parameter>
      <parameter>
        <name>START_ROW</name>
        <default_value>1</default_value>
        <description />
      </parameter>
    </parameters>
    <log>
      <trans-log-table>
        <connection />
        <schema />
        <table />
        <size_limit_lines />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STATUS</id>
          <enabled>Y</enabled>
          <name>STATUS</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
          <subject />
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
          <subject />
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
          <subject />
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
          <subject />
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
          <subject />
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>STARTDATE</id>
          <enabled>Y</enabled>
          <name>STARTDATE</name>
        </field>
        <field>
          <id>ENDDATE</id>
          <enabled>Y</enabled>
          <name>ENDDATE</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>DEPDATE</id>
          <enabled>Y</enabled>
          <name>DEPDATE</name>
        </field>
        <field>
          <id>REPLAYDATE</id>
          <enabled>Y</enabled>
          <name>REPLAYDATE</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>Y</enabled>
          <name>LOG_FIELD</name>
        </field>
        <field>
          <id>EXECUTING_SERVER</id>
          <enabled>N</enabled>
          <name>EXECUTING_SERVER</name>
        </field>
        <field>
          <id>EXECUTING_USER</id>
          <enabled>N</enabled>
          <name>EXECUTING_USER</name>
        </field>
        <field>
          <id>CLIENT</id>
          <enabled>N</enabled>
          <name>CLIENT</name>
        </field>
      </trans-log-table>
      <perf-log-table>
        <connection />
        <schema />
        <table />
        <interval />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>SEQ_NR</id>
          <enabled>Y</enabled>
          <name>SEQ_NR</name>
        </field>
        <field>
          <id>LOGDATE</id>
          <enabled>Y</enabled>
          <name>LOGDATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>INPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>INPUT_BUFFER_ROWS</name>
        </field>
        <field>
          <id>OUTPUT_BUFFER_ROWS</id>
          <enabled>Y</enabled>
          <name>OUTPUT_BUFFER_ROWS</name>
        </field>
      </perf-log-table>
      <channel-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>LOGGING_OBJECT_TYPE</id>
          <enabled>Y</enabled>
          <name>LOGGING_OBJECT_TYPE</name>
        </field>
        <field>
          <id>OBJECT_NAME</id>
          <enabled>Y</enabled>
          <name>OBJECT_NAME</name>
        </field>
        <field>
          <id>OBJECT_COPY</id>
          <enabled>Y</enabled>
          <name>OBJECT_COPY</name>
        </field>
        <field>
          <id>REPOSITORY_DIRECTORY</id>
          <enabled>Y</enabled>
          <name>REPOSITORY_DIRECTORY</name>
        </field>
        <field>
          <id>FILENAME</id>
          <enabled>Y</enabled>
          <name>FILENAME</name>
        </field>
        <field>
          <id>OBJECT_ID</id>
          <enabled>Y</enabled>
          <name>OBJECT_ID</name>
        </field>
        <field>
          <id>OBJECT_REVISION</id>
          <enabled>Y</enabled>
          <name>OBJECT_REVISION</name>
        </field>
        <field>
          <id>PARENT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>PARENT_CHANNEL_ID</name>
        </field>
        <field>
          <id>ROOT_CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>ROOT_CHANNEL_ID</name>
        </field>
      </channel-log-table>
      <step-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>TRANSNAME</id>
          <enabled>Y</enabled>
          <name>TRANSNAME</name>
        </field>
        <field>
          <id>STEPNAME</id>
          <enabled>Y</enabled>
          <name>STEPNAME</name>
        </field>
        <field>
          <id>STEP_COPY</id>
          <enabled>Y</enabled>
          <name>STEP_COPY</name>
        </field>
        <field>
          <id>LINES_READ</id>
          <enabled>Y</enabled>
          <name>LINES_READ</name>
        </field>
        <field>
          <id>LINES_WRITTEN</id>
          <enabled>Y</enabled>
          <name>LINES_WRITTEN</name>
        </field>
        <field>
          <id>LINES_UPDATED</id>
          <enabled>Y</enabled>
          <name>LINES_UPDATED</name>
        </field>
        <field>
          <id>LINES_INPUT</id>
          <enabled>Y</enabled>
          <name>LINES_INPUT</name>
        </field>
        <field>
          <id>LINES_OUTPUT</id>
          <enabled>Y</enabled>
          <name>LINES_OUTPUT</name>
        </field>
        <field>
          <id>LINES_REJECTED</id>
          <enabled>Y</enabled>
          <name>LINES_REJECTED</name>
        </field>
        <field>
          <id>ERRORS</id>
          <enabled>Y</enabled>
          <name>ERRORS</name>
        </field>
        <field>
          <id>LOG_FIELD</id>
          <enabled>N</enabled>
          <name>LOG_FIELD</name>
        </field>
      </step-log-table>
      <metrics-log-table>
        <connection />
        <schema />
        <table />
        <timeout_days />
        <field>
          <id>ID_BATCH</id>
          <enabled>Y</enabled>
          <name>ID_BATCH</name>
        </field>
        <field>
          <id>CHANNEL_ID</id>
          <enabled>Y</enabled>
          <name>CHANNEL_ID</name>
        </field>
        <field>
          <id>LOG_DATE</id>
          <enabled>Y</enabled>
          <name>LOG_DATE</name>
        </field>
        <field>
          <id>METRICS_DATE</id>
          <enabled>Y</enabled>
          <name>METRICS_DATE</name>
        </field>
        <field>
          <id>METRICS_CODE</id>
          <enabled>Y</enabled>
          <name>METRICS_CODE</name>
        </field>
        <field>
          <id>METRICS_DESCRIPTION</id>
          <enabled>Y</enabled>
          <name>METRICS_DESCRIPTION</name>
        </field>
        <field>
          <id>METRICS_SUBJECT</id>
          <enabled>Y</enabled>
          <name>METRICS_SUBJECT</name>
        </field>
        <field>
          <id>METRICS_TYPE</id>
          <enabled>Y</enabled>
          <name>METRICS_TYPE</name>
        </field>
        <field>
          <id>METRICS_VALUE</id>
          <enabled>Y</enabled>
          <name>METRICS_VALUE</name>
        </field>
      </metrics-log-table>
    </log>
    <maxdate>
      <connection />
      <table />
      <field />
      <offset>0.0</offset>
      <maxdiff>0.0</maxdiff>
    </maxdate>
    <size_rowset>10000</size_rowset>
    <sleep_time_empty>50</sleep_time_empty>
    <sleep_time_full>50</sleep_time_full>
    <unique_connections>N</unique_connections>
    <feedback_shown>Y</feedback_shown>
    <feedback_size>50000</feedback_size>
    <using_thread_priorities>Y</using_thread_priorities>
    <shared_objects_file />
    <capture_step_performance>N</capture_step_performance>
    <step_performance_capturing_delay>1000</step_performance_capturing_delay>
    <step_performance_capturing_size_limit>100</step_performance_capturing_size_limit>
    <dependencies>
    </dependencies>
    <partitionschemas>
    </partitionschemas>
    <slaveservers>
    </slaveservers>
    <clusterschemas>
    </clusterschemas>
    <created_user />
    <created_date>2018/06/23 01:17:31.064</created_date>
    <modified_user>-</modified_user>
    <modified_date>2010/09/30 20:22:22.679</modified_date>
    <key_for_session_key>H4sIAAAAAAAAAAMAAAAAAAAAAAA=</key_for_session_key>
    <is_key_private>N</is_key_private>
  </info>
  <notepads>
    <notepad>
      <note>【Table output】
truncate をon/offできるとよい</note>
      <xloc>560</xloc>
      <yloc>112</yloc>
      <width>156</width>
      <heigth>42</heigth>
      <fontname>Yu Gothic UI</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>【Extract】
・CSV用のExtractorを実装
</note>
      <xloc>320</xloc>
      <yloc>96</yloc>
      <width>138</width>
      <heigth>57</heigth>
      <fontname>Yu Gothic UI</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
    <notepad>
      <note>以下を親ktrからパラメータで受け取る
 "IN_FILE"
 "START_ROW"
 "DB_URL"
 "DB_SCHEMA"
 "DB_TABLE"
 "DB_USER"
 "DB_PASSWORD"
 "DB_PASSWORD"
</note>
      <xloc>16</xloc>
      <yloc>16</yloc>
      <width>184</width>
      <heigth>169</heigth>
      <fontname>Yu Gothic UI</fontname>
      <fontsize>9</fontsize>
      <fontbold>N</fontbold>
      <fontitalic>N</fontitalic>
      <fontcolorred>0</fontcolorred>
      <fontcolorgreen>0</fontcolorgreen>
      <fontcolorblue>0</fontcolorblue>
      <backgroundcolorred>255</backgroundcolorred>
      <backgroundcolorgreen>205</backgroundcolorgreen>
      <backgroundcolorblue>112</backgroundcolorblue>
      <bordercolorred>100</bordercolorred>
      <bordercolorgreen>100</bordercolorgreen>
      <bordercolorblue>100</bordercolorblue>
      <drawshadow>Y</drawshadow>
    </notepad>
  </notepads>
  <connection>
    <name>Derby_local_testDB</name>
    <server>localhost</server>
    <type>GENERIC</type>
    <access>Native</access>
    <database>testDB</database>
    <port>1527</port>
    <username>${DB_USER}</username>
    <password>${DB_PASS}</password>
    <servername />
    <data_tablespace />
    <index_tablespace />
    <attributes>
      <attribute>
        <code>CUSTOM_DRIVER_CLASS</code>
        <attribute>${DB_DRIVER}</attribute>
      </attribute>
      <attribute>
        <code>CUSTOM_URL</code>
        <attribute>${DB_URL}</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_LOWERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>FORCE_IDENTIFIERS_TO_UPPERCASE</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>IS_CLUSTERED</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>PORT_NUMBER</code>
        <attribute>1527</attribute>
      </attribute>
      <attribute>
        <code>PRESERVE_RESERVED_WORD_CASE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>QUOTE_ALL_FIELDS</code>
        <attribute>N</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_BOOLEAN_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>SUPPORTS_TIMESTAMP_DATA_TYPE</code>
        <attribute>Y</attribute>
      </attribute>
      <attribute>
        <code>USE_POOLING</code>
        <attribute>N</attribute>
      </attribute>
    </attributes>
  </connection>
  <order>
    <hop>
      <from>Extract</from>
      <to>Table output</to>
      <enabled>N</enabled>
    </hop>
    <hop>
      <from>Extract</from>
      <to>MyTable out</to>
      <enabled>Y</enabled>
    </hop>
  </order>
  <step>
    <name>Extract</name>
    <type>UserDefinedJavaClass</type>
    <description />
    <distribute>N</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <definitions>
      <definition>
        <class_type>TRANSFORM_CLASS</class_type>
        <class_name>Processor</class_name>
        <class_source>import java.io.BufferedReader;
import java.io.IOException;
import java.math.BigDecimal;
import java.nio.file.Files;
import java.nio.file.Path;
import java.nio.file.Paths;
import java.sql.Blob;
import java.sql.Clob;
import java.sql.Connection;
import java.sql.Date;
import java.sql.DriverManager;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.SQLException;
import java.sql.Statement;

import javax.activation.UnsupportedDataTypeException;
import java.util.*;

import org.pentaho.di.core.row.value.*;


// ------ここから
	/* ktrのパラメータとして受け取る */
	static private String PARAM_IN_FILE = "IN_FILE";
	static private String PARAM_START_ROW = "START_ROW";
	static private String PARAM_DB_URL = "DB_URL";
	static private String PARAM_DB_SCHEMA = "DB_SCHEMA";
	static private String PARAM_DB_TABLE = "DB_TABLE";
	static private String PARAM_DB_USER = "DB_USER";
	static private String PARAM_DB_PASSWORD = "DB_PASSWORD";

	/**
	 * 変換を実行する内部クラス
	 */
	private class ExtractorCSV {
		/* ktr側で設定されているパラメータ */

		private BufferedReader _reader = null;

		/**
		 * ファイルを読み込み初期化
		 * @throws KettleException
		 */
		public void init() throws KettleException {
			try {
				/* パラメータで指定されたファイルを読み込む */
				String filePathStr = getVariable(PARAM_IN_FILE);
				logBasic("In FilePath=" + filePathStr);
				Path filePath = Paths.get(filePathStr, new String[0]);
				_reader = Files.newBufferedReader(filePath);

				/* パラメータで指定された最初の行まで読み込む */
				int startRow = Integer.parseInt(getVariable(PARAM_START_ROW));
				for (int i = 0; i &lt; startRow; i++) {
					_reader.readLine();
				}

			} catch (IOException e) {
				throwAsKettleException(e);
			}
		}

		/**
		 * ファイルを1行読み込んで配列を返す.
		 *
		 * @return 読み込んだデータ。終端の場合はnul値とする。
		 */
		public String[] getRowData() throws KettleException {
			if (_reader == null) {
				return null;
			}
			String line = null;
			try {
				line = _reader.readLine();
			} catch (IOException e) {
				throwAsKettleException(e);
			}
			if (line == null) {
				return null;
			}

			String[] columnDatas = line.split(",");


			return columnDatas;
		}

		public String toUpper(String indata) {
			return indata.toUpperCase();
		}

		public void close() throws KettleException {
			if (_reader != null) {
				try {
					_reader.close();
				} catch (IOException e) {
					throwAsKettleException(e);
				}
			}
		}

		private void throwAsKettleException(Throwable e) throws KettleException {
			logError("エラーが発生", e);
			throw new KettleException(e);
		}
	}

	private ExtractorCSV _extractor = new ExtractorCSV();
	private TableColumn[] _tableColumns = null;
	private ValueMetaInterface[] _valueMetaInterfaces;

	// Kettleでエラーとなる
	// @Override
	/**
	 * 一時停止の際に呼ばれる。
	 */
	public void dispose(StepMetaInterface smi, StepDataInterface sdi) {
		super.dispose(smi, sdi);
		logBasic("Extract: dispose()");
	}
	/**
	 * 停止させた際に呼ばれる
	 */
	public void stopRunning(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
			throws KettleException {
		super.stopRunning(stepMetaInterface, stepDataInterface);
		logBasic("Extract: stopRunning()!");
		if (_extractor != null) {
			try {
				_extractor.close();
			} catch (KettleException e) {
			}
		}
	}



	/**
	 * @return 次の行へ継続する場合はtrue, 終了する場合はfalse
	 */
	public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException {
		try {
			/* 最初の1回目(1行目)はfirst == trueとなる */
			if (first) {
				//first = false;
				logBasic("first");

				/* ファイルの読み込みと初期化 */
				_extractor.init();
			}

			/* 行データを取得。最後の行はnullとなったら終了処理 */
			String[] rowData = _extractor.getRowData();
			if (rowData == null) {
				logBasic("inputRow==null");
				setOutputDone();
				_extractor.close();
				return false;
			}

			if (first) {
				first = false;
				/*
				 * 出力する列データを設定
				 *
				 * ここで出力する列データ数はinsertする列数と同じでないとエラーとなる。
				 * そのため、1行目のデータを取得時に処理を行う。
				 *
				 */
				String url = getVariable(PARAM_DB_URL);
				String user = getVariable(PARAM_DB_USER);
				String pass = getVariable(PARAM_DB_PASSWORD);
				String schema = getVariable(PARAM_DB_SCHEMA);
				String table = getVariable(PARAM_DB_TABLE);
				String schemaTable = schema + "." + table;
				_tableColumns = getTableColumn(url, user, pass, schemaTable);
				_valueMetaInterfaces = getTableValueMetaInterfaces(_tableColumns);

//				/* rowDataの数だけtableColumnsを追加する */
//				RowMetaInterface newFields = new RowMeta();
//				for (int i = 0; i &lt; rowData.length; i++) {
//					logBasic("tableColunns[" + i + "]=" + valueMetaInterfaces);
//					newFields.addValueMeta(valueMetaInterfaces[i]);
//				}
//				data.outputRowMeta.addRowMeta(newFields);
			}

			/* rowDataの数だけtableColumnsを追加する */
			RowMetaInterface newFields = new RowMeta();
			for (int i = 0; i &lt; rowData.length; i++) {
				logBasic("tableColunns[" + i + "]=" + _valueMetaInterfaces[i]);
				newFields.addValueMeta(_valueMetaInterfaces[i]);
			}
			data.outputRowMeta.clear();
			data.outputRowMeta.addRowMeta(newFields);

			/* rowDataをテーブルの型に合わせたオブジェクトに変換する */
			Object[] typedRowData = new Object[rowData.length];
			for (int i = 0; i &lt; rowData.length; i++) {
				logBasic("rowData[" + i + "]=" + rowData[i]);
				typedRowData[i] = strintToObject(rowData[i], _tableColumns[i].type);
			}

			/*
			 * 1行のデータを出力
			 */
			putRow(data.outputRowMeta, typedRowData);
			logBasic("putRow");
		} catch (Exception e) {
			logError("getTableColumns()にてエラー", e);
			throw new KettleException(e);
		}

		return true;
	}

	/**
	 * テーブルのカラムクラス
	 */
	private class TableColumn {
		public String name;
		public String type;

		public TableColumn(String name, String type) {
			this.name = name;
			this.type = type;
		}
	}

	/**
	 * 指定されたテーブルの属性項目を返します。
	 *
	 * JDBCでDBMSへ接続して型情報から生成しますので、多用しないようにする必要あり。
	 *
	 * @param url
	 * @param user
	 * @param pass
	 * @param table
	 * @return
	 */
	private TableColumn[] getTableColumn(String url, String user, String pass, String table)
			throws SQLException, IOException {
		TableColumn[] columns = null;
		// try()はKettleでエラーとなるためNG
		//		try (Connection connection = DriverManager.getConnection(url, user, pass);
		//				Statement stmt = connection.createStatement()) {

		Connection connection = null;
		try {
			connection = DriverManager.getConnection(url, user, pass);
			Statement stmt = connection.createStatement();
			ResultSet resultSet = stmt.executeQuery("select * from " + table);
			ResultSetMetaData metaData = resultSet.getMetaData();
			int columnCount = metaData.getColumnCount();
			columns = new TableColumn[columnCount];
			for (int i = 0; i &lt; columnCount; i++) {
				String colName = metaData.getColumnName(i + 1);
				String typeName = metaData.getColumnClassName(i + 1);
				logBasic("TableColumn[" + i + "]=" + colName + ", type=" + typeName);
				columns[i] = new TableColumn(colName, typeName);
			}
		} finally {
			if (connection != null) {
				connection.close();
			}
		}

		return columns;
	}

	private ValueMetaInterface[] getTableValueMetaInterfaces(TableColumn[] columns)
			throws SQLException, IOException {
		ValueMetaInterface[] vmis = new ValueMetaInterface[columns.length];
		for (int i = 0; i &lt; vmis.length; i++) {
			vmis[i] = getValueMetaInterface(columns[i].name, columns[i].type);
		}

		return vmis;
	}

	/**
	 * 指定されたカラム名とJava型情報から{@link ValueMetaInterface}を返します。
	 *
	 * Java型との対応は{@link ValueMetaInterface}のJavaDocを参照。
	 *
	 * @param colName
	 * @param typeName
	 * @return
	 * @throws UnsupportedDataTypeException
	 */
	private ValueMetaInterface getValueMetaInterface(String colName, String typeName)
			throws UnsupportedDataTypeException {
		if (Double.class.getName().equals(typeName) ||
				Float.class.getName().equals(typeName)) {
			return new ValueMetaNumber(colName);
		} else if (String.class.getName().equals(typeName)) {
			return new ValueMetaString(colName);
		} else if (Date.class.getName().equals(typeName)) {
			return new ValueMetaDate(colName);
		} else if (Boolean.class.getName().equals(typeName)) {
			return new ValueMetaBoolean(colName);
		} else if (Long.class.getName().equals(typeName) || Integer.class.getName().equals(typeName)) {
			/* Long型もValueMetaIntegerとなる */
			return new ValueMetaInteger(colName);
		} else if (BigDecimal.class.getName().equals(typeName)) {
			return new ValueMetaBigNumber(colName);
		} else if (Blob.class.getName().equals(typeName) ||
				Clob.class.getName().equals(typeName)) {
			return new ValueMetaBinary(colName);
		} else if (java.sql.Timestamp.class.getName().equals(typeName)) {
			return new ValueMetaTimestamp(colName);
		}

		throw new UnsupportedDataTypeException("Column=" + colName + ", Type=" + typeName);
	}

	private Object strintToObject(String value, String typeName) throws UnsupportedDataTypeException {
		if (String.class.getName().equals(typeName)) {
			return value;
		} else if (Integer.class.getName().equals(typeName) || Long.class.getName().equals(typeName)) {
			/* PDIではIntegerもLong型となる */
			//return Integer.valueOf(value);
			return Long.valueOf(value);
		}
		//TODO: 他の型も処理する

		throw new UnsupportedDataTypeException("Value=" + value + ", Type=" + typeName);

	}</class_source>
      </definition>
    </definitions>
    <fields>
    </fields>
    <clear_result_fields>N</clear_result_fields>
    <info_steps />
    <target_steps />
    <usage_parameters />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>352</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>MyTable out</name>
    <type>UserDefinedJavaClass</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <definitions>
      <definition>
        <class_type>TRANSFORM_CLASS</class_type>
        <class_name>Processor</class_name>
        <class_source>import java.io.IOException;
import java.sql.Connection;
import java.sql.DriverManager;
import java.sql.PreparedStatement;
import java.sql.ResultSet;
import java.sql.ResultSetMetaData;
import java.sql.SQLException;
import java.sql.Statement;

	/* ktrのパラメータとして受け取る */
	//	static private String PARAM_IN_FILE = "IN_FILE";
	//	static private String PARAM_START_ROW = "START_ROW";
	static private String PARAM_DB_URL = "DB_URL";
	static private String PARAM_DB_SCHEMA = "DB_SCHEMA";
	static private String PARAM_DB_TABLE = "DB_TABLE";
	static private String PARAM_DB_USER = "DB_USER";
	static private String PARAM_DB_PASSWORD = "DB_PASSWORD";

	private Connection _connecion;
	private int _prevColumnNum = 0;
	private TableColumn[] _tableColumns = null;
	private PreparedStatement _prepStatement = null;
	private String _schemaTableName;

	// Kettleでエラーとなる
	// @Override
	/**
	 * 一時停止の際に呼ばれる。
	 */
	public void dispose(StepMetaInterface smi, StepDataInterface sdi) {
		super.dispose(smi, sdi);
		logBasic("Extract: dispose()");
	}

	/**
	 * 停止させた際に呼ばれる
	 */
	public void stopRunning(StepMetaInterface stepMetaInterface, StepDataInterface stepDataInterface)
			throws KettleException {
		super.stopRunning(stepMetaInterface, stepDataInterface);
		logBasic("Extract: stopRunning()!");
		closeConnections(false);
	}

	/**
	 * @return 次の行へ継続する場合はtrue, 終了する場合はfalse
	 */
	public boolean processRow(StepMetaInterface smi, StepDataInterface sdi) throws KettleException {
		try {
			/* 最初の1回目(1行目)はfirst == trueとなる */
			if (first) {
				first = false;
				logBasic("first");

				/* Connectionの確立 */
				String url = getVariable(PARAM_DB_URL);
				String user = getVariable(PARAM_DB_USER);
				String pass = getVariable(PARAM_DB_PASSWORD);
				String schema = getVariable(PARAM_DB_SCHEMA);
				String table = getVariable(PARAM_DB_TABLE);
				_schemaTableName = schema + "." + table;

				_tableColumns = getTableColumn(url, user, pass, _schemaTableName);
				_connecion = getConnection(url, user, pass);

			}

			Object[] rowData = getRow();
			if (rowData == null) {
				logBasic("inputRow==null");
				setOutputDone();
				closeConnections(true);
				return false;
			}

			if (_prevColumnNum != rowData.length) {
				if (_prepStatement != null) {
					_prepStatement.close();
				}
				_prepStatement = createPreparedStatement(_schemaTableName, _tableColumns, rowData.length, _connecion);
			}
			for (int i = 0; i &lt; rowData.length; i++) {
				logBasic("rowData[" + i + "]=" + rowData[i]);
				_prepStatement.setObject(i + 1, rowData[i]);
			}
			_prepStatement.executeUpdate();

		} catch (Exception e) {
			logError("getTableColumns()にてエラー", e);
			closeConnections(false);
			throw new KettleException(e);
		}

		return true;
	}

	private Connection getConnection(String url, String user, String pass) throws SQLException {
		Connection connection = DriverManager.getConnection(url, user, pass);
		connection.setAutoCommit(false);
		return connection;
	}

	private void closeConnections(boolean doCommit) {
		if (_prepStatement != null) {
			try {
				_prepStatement.close();
			} catch (SQLException e) {
				logError("close中にエラー", e);
			}
		}
		if (_connecion != null) {
			if (doCommit) {
				try {
					_connecion.commit();
				} catch (SQLException e) {
					logError("close中にエラー", e);
				}
			}
			else {
				try {
					_connecion.rollback();
				} catch (SQLException e) {
					logError("close中にエラー", e);
				}
			}
			try {
				_connecion.close();
			} catch (SQLException e) {
				logError("close中にエラー", e);
			}
		}
	}

	/**
	 * テーブルのカラムクラス
	 */
	private class TableColumn {
		public String name;
		public String type;

		public TableColumn(String name, String type) {
			this.name = name;
			this.type = type;
		}
	}

	/**
	 * 指定されたテーブルの属性項目を返します。
	 *
	 * JDBCでDBMSへ接続して型情報から生成しますので、多用しないようにする必要あり。
	 *
	 * @param url
	 * @param user
	 * @param pass
	 * @param table
	 * @return
	 */
	private TableColumn[] getTableColumn(String url, String user, String pass, String table)
			throws SQLException, IOException {
		TableColumn[] columns = null;
		// try()はKettleでエラーとなるためNG
		//		try (Connection connection = DriverManager.getConnection(url, user, pass);
		//				Statement stmt = connection.createStatement()) {

		Connection connection = null;
		try {
			connection = DriverManager.getConnection(url, user, pass);
			Statement stmt = connection.createStatement();
			ResultSet resultSet = stmt.executeQuery("select * from " + table);
			ResultSetMetaData metaData = resultSet.getMetaData();
			int columnCount = metaData.getColumnCount();
			columns = new TableColumn[columnCount];
			for (int i = 0; i &lt; columnCount; i++) {
				String colName = metaData.getColumnName(i + 1);
				String typeName = metaData.getColumnClassName(i + 1);
				logBasic("TableColumn[" + i + "]=" + colName + ", type=" + typeName);
				columns[i] = new TableColumn(colName, typeName);
			}
		} finally {
			if (connection != null) {
				connection.close();
			}
		}

		return columns;
	}

	private PreparedStatement createPreparedStatement(String table, TableColumn[] allColumns, int columnNum,
			Connection con) throws SQLException {
		StringBuffer sql = new StringBuffer();
		sql.append("INSERT INTO " + table + "(");
		for (int i = 0; i &lt; columnNum; i++) {
			if (i != 0) {
				sql.append(",");
			}
			sql.append(allColumns[i].name);
		}
		sql.append(") VALUES(");
		for (int i = 0; i &lt; columnNum; i++) {
			if (i != 0) {
				sql.append(",");
			}
			sql.append("?");
		}
		sql.append(")");
		logBasic("SQL=" + sql.toString());

		PreparedStatement prep = con.prepareStatement(sql.toString());

		return prep;
	}
</class_source>
      </definition>
    </definitions>
    <fields>
    </fields>
    <clear_result_fields>N</clear_result_fields>
    <info_steps />
    <target_steps />
    <usage_parameters />
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>608</xloc>
      <yloc>272</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step>
    <name>Table output</name>
    <type>TableOutput</type>
    <description />
    <distribute>Y</distribute>
    <custom_distribution />
    <copies>1</copies>
    <partitioning>
      <method>none</method>
      <schema_name />
    </partitioning>
    <connection>Derby_local_testDB</connection>
    <schema>${DB_SCHEMA}</schema>
    <table>${DB_TABLE}</table>
    <commit>1</commit>
    <truncate>Y</truncate>
    <ignore_errors>Y</ignore_errors>
    <use_batch>N</use_batch>
    <specify_fields>N</specify_fields>
    <partitioning_enabled>N</partitioning_enabled>
    <partitioning_field />
    <partitioning_daily>N</partitioning_daily>
    <partitioning_monthly>Y</partitioning_monthly>
    <tablename_in_field>N</tablename_in_field>
    <tablename_field />
    <tablename_in_table>N</tablename_in_table>
    <return_keys>N</return_keys>
    <return_field />
    <fields>
    </fields>
    <cluster_schema />
    <remotesteps>
      <input>
      </input>
      <output>
      </output>
    </remotesteps>
    <GUI>
      <xloc>608</xloc>
      <yloc>192</yloc>
      <draw>Y</draw>
    </GUI>
  </step>
  <step_error_handling>
  </step_error_handling>
  <slave-step-copy-partition-distribution>
  </slave-step-copy-partition-distribution>
  <slave_transformation>N</slave_transformation>
</transformation>
